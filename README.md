# Asistente de Normativa - Prototipo

Un asistente virtual inteligente para consultas sobre normativa t√©cnica en espa√±ol, implementado con RAG (Retrieval-Augmented Generation) y optimizado para el flujo de trabajo de base de conocimiento en ingl√©s y respuestas en espa√±ol.

## Caracter√≠sticas Principales

- **Procesamiento de PDFs**: Extracci√≥n inteligente de texto, tablas e im√°genes usando Mistral OCR
- **B√∫squeda Vectorial**: B√∫squeda de similitud sem√°ntica usando Qdrant vector database
- **Respuestas con IA**: Respuestas contextuales usando modelos Mistral LLM
- **Multiling√ºe**: Base de conocimiento en ingl√©s, interfaz y respuestas en espa√±ol
- **Interfaz Web**: Chat interactivo con Chainlit
- **Validaci√≥n Autom√°tica**: Scripts de validaci√≥n de completitud de ingesti√≥n
- **An√°lisis de Documentos**: Herramientas de an√°lisis y detecci√≥n de duplicados

## Arquitectura

### Componentes Principales

1. **Ingesti√≥n de Documentos** (`src/ingestion/`)
   - Extracci√≥n de texto con Mistral OCR (modelo `mistral-ocr-latest`)
   - Procesamiento inteligente de PDFs con preservaci√≥n de im√°genes
   - Chunking inteligente con MarkdownHeaderTextSplitter
   - Contextualizaci√≥n autom√°tica con Mistral AI

2. **Embeddings y Vectorizaci√≥n** (`src/embeddings/`)
   - Generaci√≥n de embeddings con modelo Ollama `nomic-embed-text`
   - Almacenamiento vectorial en Qdrant con configuraci√≥n autom√°tica
   - B√∫squeda de similitud sem√°ntica con distancia Cosine
   - Configuraci√≥n: 768 dimensiones, almacenamiento en disco

3. **Modelos de Lenguaje** (`src/llm/`)
   - Integraci√≥n con Mistral AI (`mistral-small-latest`)
   - Procesamiento RAG optimizado con prompts centralizados
   - Respuestas siempre en espa√±ol para el usuario
   - Sistema de prompts configurable por idioma

4. **Interfaz de Usuario** (`src/`)
   - Frontend web con Chainlit
   - Configuraci√≥n de visualizaci√≥n centralizada
   - Sistema de traducci√≥n autom√°tica (espa√±ol ‚Üî ingl√©s)
   - Manejo de errores y sugerencias de seguimiento

5. **Configuraci√≥n y Gesti√≥n** (`src/config/`)
   - Configuraci√≥n de visualizaci√≥n centralizada
   - Gesti√≥n de prompts por idioma
   - Configuraci√≥n de elementos visuales y mensajes

6. **An√°lisis y Evaluaci√≥n** (`src/analysis/`, `src/evaluation/`)
   - An√°lisis de PDFs con PyMuPDF y PyPDF2
   - Detecci√≥n de duplicados inteligente
   - Evaluaci√≥n RAG con m√©tricas RAGAS
   - Generaci√≥n de reportes Excel y JSON

## Requisitos

### Dependencias del Sistema
- **Python 3.12+** - Lenguaje principal del proyecto
- **uv** - Gestor de paquetes y entornos virtuales de Python
- **Node.js** - Runtime de JavaScript para herramientas de desarrollo
- **npm** - Gestor de paquetes de Node.js
- **npx** - Ejecutor de paquetes de Node.js
- **Docker** - Contenedores para Qdrant, PostgreSQL, Ollama y LocalStack
- **Docker Compose** - Orquestaci√≥n de m√∫ltiples contenedores
- **Memoria RAM**: 8GB+ recomendado

### Versiones de Dependencias
- **Chainlit**: <2.6.0 (versi√≥n estable sin problemas de data layer)
- **Python**: 3.12+
- **Qdrant**: latest
- **Ollama**: latest
- **Mistral AI**: API v1

### Herramientas de Desarrollo
- **uv**: Gestor de paquetes Python moderno y r√°pido
- **Node.js**: Para ejecutar Prisma Studio y herramientas de desarrollo
- **npm/npx**: Gesti√≥n de dependencias de Node.js y ejecuci√≥n de Prisma
- **Docker**: Contenedores para todos los servicios (Qdrant, PostgreSQL, Ollama, LocalStack)

### Variables de Entorno
```bash
# Mistral AI
MISTRAL_API_KEY=your_mistral_api_key

# Qdrant
QDRANT_COLLECTION_NAME=asistente-normativa-sincro-kb

# Configuraci√≥n de PDFs
PDF_FOLDER_PATH=../data/test

# Base de Datos (opcional)
DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# AWS LocalStack (opcional)
BUCKET_NAME=my-bucket
APP_AWS_ACCESS_KEY=random-key
APP_AWS_SECRET_KEY=random-key
APP_AWS_REGION=eu-central-1
DEV_AWS_ENDPOINT=http://localhost:4566
```

## Instalaci√≥n y Configuraci√≥n

### 1. Clonar el Repositorio
   ```bash
   git clone <repository-url>
   cd ai-genai-contextual-rag-construction-regulatory-chatbot
   ```

### 2. Instalar Dependencias
   ```bash
   uv sync
   ```
Esto crea el entorno virtual y el archivo uv.lock

### 3. Configurar Entorno Virtual
   ```bash
   source .venv/bin/activate
```

### 4. Crear el archivo .env con las variables de entorno

### ‚ö†Ô∏è Nota Importante sobre Herramientas
**Todas las herramientas del sistema deben estar instaladas antes de proceder:**
- **uv**: Necesario para `uv sync` y gesti√≥n de dependencias Python
- **Node.js/npm**: Requerido para ejecutar `npx prisma studio`
- **Docker**: Esencial para todos los servicios (Qdrant, PostgreSQL, Ollama, LocalStack)
- **Ollama**: Necesario para embeddings locales con `nomic-embed-text`

## Despliegue de la soluci√≥n

### Requisitos Previos
- Docker y Docker Compose instalados
- Variables de entorno configuradas

### Servicios Requeridos para la Soluci√≥n Completa
La soluci√≥n requiere **6 servicios principales** funcionando simult√°neamente:

1. **Chainlit-datalayer** - Gesti√≥n de base de datos y servicios AWS
2. **PostgreSQL** - Base de datos principal para Chainlit
3. **Qdrant** - Base de datos vectorial para embeddings
4. **Ollama** - Modelo de embeddings local (nomic-embed-text)
5. **LocalStack** - Emulaci√≥n de servicios AWS
6. **Chainlit Assistant** - Aplicaci√≥n principal RAG

### Contenedores Requeridos

#### A. CHAINLIT-DATALAYER
Dentro del proyecto se necesita ejecutar lo siguiente:

   ```bash
# 1. Iniciar el contenedor: chainlit-datalayer
docker-compose up -d

# 2. Configurar variable de entorno
export DATABASE_URL=postgresql://root:root@localhost:5432/postgres

# 3. Ejecutar Prisma Studio
npx prisma studio
```

Se debe asegurar que los contenedores de QDRANT y OLLAMA est√©n corriendo:

#### B. QDRANT
```bash
# Iniciar contenedor Qdrant
docker run -p 6333:6333 qdrant/qdrant:dev
```

#### C. OLLAMA
```bash
# Iniciar contenedor Ollama para embeddings
docker run -d -p 11434:11434 --name ollama ollama/ollama:latest
```
**Nota**: No se necesita instalar nada. El modelo `nomic-embed-text` ya est√° disponible en el contenedor.

#### D. AI-GENAI-CONTEXTUAL-RAG-CONSTRUCTION-REGULATORY-CHATBOT
Una vez que los contenedores est√©n corriendo, ejecutar la aplicaci√≥n:

```bash
# 1. Entrar al directorio src
cd src

# 2. Ejecutar la aplicaci√≥n Chainlit
chainlit run frontend_rag.py --host 0.0.0.0 --port 8000
```

### Puertos de Despliegue

| Servicio | URL | Puerto | Descripci√≥n |
|----------|-----|--------|-------------|
| **Chainlit Assistant** | http://localhost:8000/ | 8000 | Interfaz principal del asistente RAG |
| **Qdrant Dashboard** | http://localhost:6333/dashboard | 6333 | Base de datos vectorial |
| **Prisma Studio** | http://localhost:5555/ | 5555 | Gesti√≥n de base de datos PostgreSQL |
| **PostgreSQL** | localhost:5432 | 5432 | Base de datos principal del sistema |
| **Ollama** | http://localhost:11434/ | 11434 | Servicio de embeddings locales |
| **LocalStack** | http://localhost:4566/ | 4566 | Emulaci√≥n de servicios AWS |

### Verificaci√≥n de Contenedores
```bash
# Verificar estado de todos los contenedores
docker ps

# Verificar logs de contenedores espec√≠ficos
docker logs <container_name>

# Verificar conectividad de servicios
curl http://localhost:6333/collections  # Qdrant
curl http://localhost:8000/             # Chainlit
curl http://localhost:5555/             # Prisma Studio
curl http://localhost:5432              # PostgreSQL
curl http://localhost:11434/api/tags    # Ollama
curl http://localhost:4566/health       # LocalStack
```

### Verificaci√≥n Completa de Servicios
```bash
# Script de verificaci√≥n autom√°tica
echo "üîç Verificando estado de todos los servicios..."
echo "================================================"

# Qdrant
echo "üìä Qdrant (Puerto 6333):"
curl -s http://localhost:6333/collections | jq '.status' 2>/dev/null || echo "‚ùå No disponible"

# PostgreSQL
echo "üóÑÔ∏è  PostgreSQL (Puerto 5432):"
pg_isready -h localhost -p 5432 2>/dev/null && echo "‚úÖ Conectado" || echo "‚ùå No disponible"

# Ollama
echo "ü§ñ Ollama (Puerto 11434):"
curl -s http://localhost:11434/api/tags | grep -o '"name":"[^"]*"' | head -1 2>/dev/null && echo "‚úÖ Disponible" || echo "‚ùå No disponible"

# LocalStack
echo "‚òÅÔ∏è  LocalStack (Puerto 4566):"
curl -s -o /dev/null -w "%{http_code}" http://localhost:4566/ 2>/dev/null | grep -q "200" && echo "‚úÖ Disponible" || echo "‚ùå No disponible"

echo "================================================"
echo "‚úÖ Verificaci√≥n completada"

# Resumen de estado
echo ""
echo "üìä RESUMEN DE ESTADO:"
echo "====================="
echo "üìä Qdrant: ‚úÖ Base de datos vectorial operativa"
echo "üóÑÔ∏è  PostgreSQL: ‚úÖ Base de datos principal operativa"
echo "ü§ñ Ollama: ‚úÖ Modelo de embeddings disponible"
echo "‚òÅÔ∏è  LocalStack: ‚úÖ Servicios AWS emulados"
echo "üéØ Chainlit: ‚ö†Ô∏è  Verificar manualmente (puerto 8000)"
echo "üìã Prisma Studio: ‚ö†Ô∏è  Verificar manualmente (puerto 5555)"
```

### Mejores Pr√°cticas de Despliegue
```bash
# 1. Verificar todos los servicios antes de iniciar
docker ps | grep -E "(qdrant|postgres|localstack)"

# 2. Verificar variables de entorno
cat .env | grep -E "(MISTRAL|QDRANT|DATABASE)"

# 3. Verificar conectividad de servicios
curl -s http://localhost:6333/collections  # Qdrant
curl -s http://localhost:5432              # PostgreSQL
curl -s http://localhost:11434             # Ollama

# 4. Iniciar servicios en orden correcto
# Primero: chainlit-datalayer (PostgreSQL + LocalStack)
# Segundo: Qdrant
# Tercero: Ollama
# Cuarto: Aplicaci√≥n principal
```

## Proceso de Ingesti√≥n de Documentos

### Flujo de Ingesti√≥n
1. **Preparaci√≥n**: Colocar PDFs en `data/test/`
2. **Procesamiento**: Ejecutar script de ingesti√≥n llamado *ingestion_manual_mistral.py*
3. **Validaci√≥n**: Verificar completitud con monitor
4. **Verificaci√≥n**: Confirmar datos en Qdrant

### Scripts de Ingesti√≥n Disponibles

#### **Script Principal (Funciona Correctamente)**
```bash
# Ingesti√≥n manual directa - FUNCIONA PERFECTAMENTE
python3 src/ingestion_manual_mistral.py
```
**Caracter√≠sticas:**
- Procesa todos los PDFs en `data/test/`
- Genera embeddings y los almacena en Qdrant
- Crea archivos de salida en `src/output/rag/`
- **Recomendado para uso directo**

#### **Script Robusto (Con Monitoreo)**
```bash
# Gestor robusto con monitoreo de salud del sistema
python3 scripts/robust_ingestion_manager.py
```
**Caracter√≠sticas:**
- Monitoreo de salud del VPS
- Manejo de timeouts y reintentos
- Logs detallados de proceso
- **Requiere configuraci√≥n adicional**

#### **Monitor de Estado**
```bash
# Verificar estado de ingesti√≥n
python3 scripts/ingestion_monitor.py
```
**Caracter√≠sticas:**
- Estado de Qdrant y colecciones
- Conteo de archivos procesados
- **NUEVO**: Verificaci√≥n b√°sica de integridad de chunks
- Salud del sistema
- Recomendaciones autom√°ticas

#### **Validador de Integridad**  **CR√çTICO**
```bash
# Validaci√≥n exhaustiva de integridad
python3 scripts/validate_ingestion_integrity.py
```
**Caracter√≠sticas:**
- Verifica que todos los chunks generados est√©n en Qdrant
- An√°lisis por archivo individual
- Verificaci√≥n de metadata (t√≠tulos, p√°ginas, chunk_ids)
- Reporte detallado de integridad
- **OBLIGATORIO ejecutar despu√©s de cada ingesti√≥n**

### **Flujo Recomendado de Validaci√≥n**
```bash
# 1. Ejecutar ingesti√≥n
python3 src/ingestion_manual_mistral.py

# 2. Verificaci√≥n r√°pida
python3 scripts/ingestion_monitor.py

# 3. Validaci√≥n exhaustiva (CR√çTICO)
python3 scripts/validate_ingestion_integrity.py
```

### Estructura de Salida Organizada
```
src/output/
‚îú‚îÄ‚îÄ rag/                    # Salidas de procesamiento RAG
‚îÇ   ‚îú‚îÄ‚îÄ enhanced_chunks_v2_*.json    # Chunks procesados
‚îÇ   ‚îú‚îÄ‚îÄ contextualized_content.json  # Contenido contextualizado
‚îÇ   ‚îî‚îÄ‚îÄ ingestion_manager_*.log      # Logs del gestor
‚îú‚îÄ‚îÄ analysis/              # Reportes de an√°lisis
‚îÇ   ‚îú‚îÄ‚îÄ normativa_analysis_report.xlsx
‚îÇ   ‚îî‚îÄ‚îÄ duplicate_analysis_report.xlsx
‚îî‚îÄ‚îÄ evaluation/            # Resultados de evaluaci√≥n
    ‚îú‚îÄ‚îÄ evaluation_results_*.json
    ‚îî‚îÄ‚îÄ evaluation_summary_*.txt
```

### Notas Importantes para ML Engineers
- **El script manual funciona perfectamente** cuando se ejecuta directamente
- **El gestor robusto puede tener problemas** de subproceso
- **Siempre verificar la salida** en `src/output/rag/`
- **Monitorear logs** para detectar errores
- **Qdrant debe estar corriendo** antes de iniciar ingesti√≥n


## Uso

### Ingesti√≥n de Documentos
```bash
cd src/
python3 ingestion_manual_mistral.py
```

### Frontend Web
```bash
cd src/
chainlit run frontend_rag.py --host 0.0.0.0 --port 8000
```

### Validaci√≥n de Ingesti√≥n
```bash
# Verificar estado de ingesti√≥n
python3 scripts/ingestion_monitor.py

# Ejecutar ingesti√≥n manual (funciona correctamente)
python3 src/ingestion_manual_mistral.py

# Ejecutar ingesti√≥n robusta (con monitoreo)
python3 scripts/robust_ingestion_manager.py
```

### An√°lisis de Documentos
```bash
cd src/analysis/
python3 pdf_analyzer.py
python3 duplicate_detector.py
```

### Evaluaci√≥n RAG
```bash
cd src/evaluation/
python3 evaluate_rag.py
```

## üìÅ Estructura del Proyecto

```
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ ingestion/                    # Procesamiento de documentos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ingest_mistral.py        # Controlador principal de ingesti√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ pdf_processor.py         # Procesamiento de PDFs
‚îÇ   ‚îú‚îÄ‚îÄ embeddings/                   # Vectorizaci√≥n y b√∫squeda
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ embedding_qdrant.py      # Controlador de embeddings con Qdrant
‚îÇ   ‚îú‚îÄ‚îÄ llm/                         # Modelos de lenguaje
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mistral_llm.py           # Integraci√≥n con Mistral AI
‚îÇ   ‚îú‚îÄ‚îÄ translation/                  # Traducci√≥n autom√°tica
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ translate.py             # Servicio de traducci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ config/                      # Configuraci√≥n
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ display_config.py        # Configuraci√≥n de interfaz
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ prompt_config.py         # Prompts del sistema
‚îÇ   ‚îú‚îÄ‚îÄ analysis/                    # An√°lisis de documentos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pdf_analyzer.py          # An√°lisis de PDFs
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ duplicate_detector.py    # Detecci√≥n de duplicados
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/                  # Evaluaci√≥n RAG
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ evaluate_rag.py          # Evaluaci√≥n principal
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation_ragas.py      # M√©tricas RAGAS
‚îÇ   ‚îú‚îÄ‚îÄ output/                      # Salidas organizadas
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ rag/                     # Salidas de procesamiento RAG
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ analysis/                # Reportes de an√°lisis
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ evaluation/              # Resultados de evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ frontend_rag.py              # Interfaz web principal
‚îÇ   ‚îî‚îÄ‚îÄ ingestion_manual_mistral.py  # Script de ingesti√≥n manual
‚îú‚îÄ‚îÄ scripts/                         # Scripts de utilidad
‚îÇ   ‚îú‚îÄ‚îÄ ingestion_monitor.py               # Monitoreo de estado de ingesti√≥n
‚îÇ   ‚îú‚îÄ‚îÄ robust_ingestion_manager.py        # Gestor robusto de ingesti√≥n para VPS
‚îÇ   ‚îî‚îÄ‚îÄ validate_ingestion_integrity.py    # Validador exhaustivo de integridad
‚îú‚îÄ‚îÄ data/                            # Documentos PDF
‚îÇ   ‚îî‚îÄ‚îÄ test/                        # Carpeta de documentos de prueba
‚îî‚îÄ‚îÄ chainlit.md                      # Configuraci√≥n de Chainlit
```

## Configuraci√≥n Avanzada

### Optimizaci√≥n de Embeddings
- **Modelo**: `nomic-embed-text` (Ollama local)
- **Dimensiones**: 768
- **Top-K**: 5 (configurable)
- **Distancia**: Cosine similarity

### Configuraci√≥n de Chunks
- **Tama√±o**: 1000 caracteres (configurable)
- **Solapamiento**: 200 caracteres
- **Contextualizaci√≥n**: Autom√°tica con Mistral AI
- **Preservaci√≥n**: Headers Markdown y estructura visual

### Configuraci√≥n de Qdrant
- **Vector Size**: 768 dimensiones
- **Distance**: Cosine
- **Storage**: On-disk payload
- **Auto-creation**: Colecciones creadas autom√°ticamente

### Flujo de Trabajo RAG
1. **Detecci√≥n de Idioma**: Autom√°tica (espa√±ol/ingl√©s)
2. **B√∫squeda**: Siempre en base de conocimiento en ingl√©s
3. **Respuesta**: Siempre en espa√±ol
4. **Optimizaci√≥n**: Contexto en ingl√©s + pregunta en ingl√©s para mejor rendimiento

## Evaluaci√≥n y M√©tricas

### M√©tricas RAGAS
- **Context Recall**: Precisi√≥n del contexto recuperado
- **Answer Relevancy**: Relevancia de la respuesta
- **Faithfulness**: Fidelidad al contexto

### Validaci√≥n de Ingesti√≥n
- **Verificaci√≥n de Completitud**: Compara archivos originales vs. ingestados
- **Validaci√≥n de T√≠tulos**: Verifica coincidencia de nombres de archivos
- **Conteo de P√°ginas**: Compara p√°ginas originales vs. procesadas
- **Reportes Detallados**: Genera an√°lisis completo de ingesti√≥n

### Ejecutar Evaluaci√≥n
```bash
cd src/evaluation/
python3 evaluate_rag.py
```

## Soluci√≥n de Problemas

### Errores Comunes de Despliegue
1. **Error de conexi√≥n a Qdrant**: Verificar que el contenedor est√© ejecut√°ndose
2. **Error de API Mistral**: Verificar la clave API en .env
3. **Error de Ollama**: Verificar que el modelo `nomic-embed-text` est√© descargado
4. **Error de memoria**: Aumentar RAM o reducir batch_size
5. **Error de puertos**: Verificar que los puertos 8000, 6333, 5555 no est√©n ocupados
6. **Error de base de datos**: Verificar que PostgreSQL est√© ejecut√°ndose en chainlit-datalayer
7. **Error de uv**: Verificar que uv est√© instalado y en PATH
8. **Error de Node.js**: Verificar que node y npm est√©n instalados
9. **Error de Docker**: Verificar que Docker est√© ejecut√°ndose y el usuario est√© en grupo docker
10. **Error de Prisma**: Verificar que npx est√© disponible y la base de datos est√© accesible

### Problemas Conocidos con Chainlit 2.6.0+
**IMPORTANTE**: Las versiones 2.6.0+ de Chainlit incluyen un data layer que requiere dependencias de Google Cloud Storage.

#### Soluci√≥n 1: Usar variable de entorno (Recomendado)
```bash
CHAINLIT_DISABLE_DATA_LAYER=true chainlit run frontend_rag.py --host 0.0.0.0 --port 8000
```

#### Soluci√≥n 2: Eliminar configuraci√≥n autom√°tica
```bash
rm -rf .chainlit/
```

#### Soluci√≥n 3: Downgrade a versi√≥n estable (Recomendado)
```bash
uv remove chainlit
uv add "chainlit<2.6.0"
```

**NOTA**: La versi√≥n <2.6.0 es la versi√≥n estable recomendada que no tiene problemas de data layer.

### Problemas de Ingesti√≥n
1. **Script robusto no funciona**: Usar `src/ingestion_manual_mistral.py` directamente
2. **No se crean archivos de salida**: Verificar permisos y directorio `src/output/rag/`
3. **Qdrant no almacena datos**: Verificar conectividad y estado del contenedor
4. **Timeout en procesamiento**: Aumentar timeout o usar script manual

### Logs y Debugging
- Los logs se muestran en la consola
- Usar `print()` para debugging en desarrollo
- Verificar conectividad de servicios con `docker ps`
- Usar scripts de validaci√≥n para verificar estado
- Monitorear logs en `src/output/rag/ingestion_manager_*.log`

### Troubleshooting de Chainlit
```bash
# Verificar versi√≥n instalada
chainlit --version

# Verificar si hay configuraci√≥n autom√°tica
ls -la .chainlit/

# Limpiar configuraci√≥n autom√°tica
rm -rf .chainlit/

# Verificar puerto 8000
lsof -ti:8000 | xargs kill -9

# Ejecutar con data layer deshabilitado
CHAINLIT_DISABLE_DATA_LAYER=true chainlit run frontend_rag.py --host 0.0.0.0 --port 8000
```

### Validaci√≥n de Estado
```bash
# Verificar estado de Qdrant
curl http://localhost:6333/collections

# Verificar estado de ingesti√≥n
python3 scripts/ingestion_monitor.py

# Verificar logs de ingesti√≥n
tail -f src/output/rag/ingestion_manager_*.log
```

## Contribuci√≥n

1. Fork el proyecto
2. Crear una rama feature (`git checkout -b feature/AmazingFeature`)
3. Commit los cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## Licencia

Este proyecto est√° bajo la Licencia MIT. Ver `LICENSE` para m√°s detalles.

## Contacto

- **Desarrollador**: Laren Osorio Toribio
- **Email**: losorio@rcp.pe
- **Organizaci√≥n**: RCP

## Changelog

### v0.2.1 (Actual)
- **Actualizaci√≥n de Chainlit**: Versi√≥n 2.6.9 con troubleshooting documentado
- **Soluci√≥n de problemas de data layer**: Documentaci√≥n de soluciones alternativas
- **Mejoras en validaci√≥n**: Scripts de verificaci√≥n de integridad mejorados
- **Troubleshooting completo**: Gu√≠as para problemas comunes de despliegue

### v0.2.0
- **Nueva colecci√≥n Qdrant**: `asistente-normativa-sincro-kb`
- **Sistema de validaci√≥n**: Scripts de verificaci√≥n de completitud de ingesti√≥n
- **Organizaci√≥n de salidas**: Estructura organizada en `src/output/`
- **Mejoras en ingesti√≥n**: Procesamiento optimizado con Mistral OCR
- **Configuraci√≥n centralizada**: Gesti√≥n unificada de prompts y visualizaci√≥n
- **An√°lisis de documentos**: Herramientas de an√°lisis y detecci√≥n de duplicados

### v0.1.0
- Migraci√≥n completa de Pinecone a Qdrant
- Migraci√≥n de Groq a Mistral AI
- Implementaci√≥n de flujo de trabajo ingl√©s KB + espa√±ol Q&A
- Interfaz web con Chainlit
- Sistema de evaluaci√≥n RAG
- Procesamiento OCR con Mistral
- Chunking contextualizado inteligente

### Pr√≥ximas Versiones
- **v0.3.0**: Optimizaci√≥n de embeddings y cache de respuestas
- **v0.4.0**: M√©tricas de rendimiento en tiempo real
- **v0.5.0**: Integraci√≥n con m√°s fuentes de datos
- **v0.6.0**: Sistema de versionado de documentos
- **v0.7.0**: API REST completa con FastAPI