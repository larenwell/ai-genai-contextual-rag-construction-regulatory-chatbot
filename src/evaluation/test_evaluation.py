#!/usr/bin/env python3
"""
Script de prueba para la evaluaciÃ³n RAG con RAGAS
================================================

Este script verifica que todos los componentes estÃ©n funcionando correctamente
antes de ejecutar la evaluaciÃ³n completa.
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv

# Agregar el directorio src al path
sys.path.append(str(Path(__file__).parent.parent))

# Agregar directorio global para langchain_mistralai
sys.path.append('/usr/local/lib/python3.12/dist-packages')

# Cargar variables de entorno
load_dotenv(Path(__file__).parent.parent.parent / '.env')

def test_imports():
    """Prueba que todas las dependencias estÃ©n disponibles"""
    print("ğŸ” Verificando dependencias...")
    
    try:
        import ragas
        print("âœ… RAGAS importado correctamente")
    except ImportError as e:
        print(f"âŒ Error importando RAGAS: {e}")
        return False
    
    try:
        import requests
        print("âœ… Requests importado correctamente")
    except ImportError as e:
        print(f"âŒ Error importando requests: {e}")
        return False
    
    try:
        import pandas as pd
        print("âœ… Pandas importado correctamente")
    except ImportError as e:
        print(f"âŒ Error importando pandas: {e}")
        return False
    
    try:
        from langchain_community.llms import Ollama
        print("âœ… LangChain Ollama importado correctamente")
    except ImportError as e:
        print(f"âŒ Error importando LangChain Ollama: {e}")
        return False
    
    return True

def test_environment():
    """Verifica las variables de entorno necesarias"""
    print("\nğŸ” Verificando variables de entorno...")
    
    mistral_key = os.getenv("MISTRAL_API_KEY")
    if mistral_key:
        print("âœ… MISTRAL_API_KEY configurada")
    else:
        print("âŒ MISTRAL_API_KEY no configurada")
        return False
    
    return True

def test_dataset():
    """Verifica que el dataset estÃ© disponible"""
    print("\nğŸ” Verificando dataset...")
    
    dataset_path = Path(__file__).parent / "data" / "evaluation_dataset.jsonl"
    
    if dataset_path.exists():
        print(f"âœ… Dataset encontrado: {dataset_path}")
        
        # Contar lÃ­neas
        with open(dataset_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        print(f"âœ… Dataset contiene {len(lines)} preguntas")
        return True
    else:
        print(f"âŒ Dataset no encontrado: {dataset_path}")
        return False

def test_api_connection():
    """Prueba la conexiÃ³n a la API"""
    print("\nğŸ” Verificando conexiÃ³n a API...")
    
    try:
        import requests
        response = requests.get("http://localhost:8001/docs", timeout=5)
        if response.status_code == 200:
            print("âœ… API RAG estÃ¡ disponible")
            return True
        else:
            print(f"âŒ API respondiÃ³ con cÃ³digo {response.status_code}")
            return False
    except requests.exceptions.RequestException as e:
        print(f"âŒ API no disponible: {e}")
        print("ğŸ’¡ Inicia la API con: cd src/evaluation && python api_rag.py")
        return False

def test_ragas_config():
    """Prueba la configuraciÃ³n de RAGAS"""
    print("\nğŸ” Verificando configuraciÃ³n RAGAS...")
    
    try:
        from ragas.llms import LangchainLLMWrapper
        from ragas.embeddings import LangchainEmbeddingsWrapper
        from langchain_mistralai import ChatMistralAI as LangChainMistralAI
        from langchain_community.embeddings import OllamaEmbeddings as LangChainOllamaEmbeddings
        
        # Verificar que se pueden crear las instancias
        mistral_key = os.getenv("MISTRAL_API_KEY")
        if mistral_key:
            mistral_langchain = LangChainMistralAI(api_key=mistral_key, model="mistral-large-latest")
            llm = LangchainLLMWrapper(mistral_langchain)
            print("âœ… MistralAI configurado correctamente")
        
        ollama_langchain = LangChainOllamaEmbeddings(model="nomic-embed-text", base_url="http://localhost:11434")
        embeddings = LangchainEmbeddingsWrapper(ollama_langchain)
        print("âœ… OllamaEmbeddings configurado correctamente")
        
        return True
        
    except Exception as e:
        print(f"âŒ Error configurando RAGAS: {e}")
        return False

def main():
    """FunciÃ³n principal de prueba"""
    print("ğŸš€ PRUEBA DE EVALUACIÃ“N RAG CON RAGAS")
    print("=" * 50)
    
    tests = [
        ("Dependencias", test_imports),
        ("Variables de entorno", test_environment),
        ("Dataset", test_dataset),
        ("ConexiÃ³n API", test_api_connection),
        ("ConfiguraciÃ³n RAGAS", test_ragas_config)
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\nğŸ“‹ {test_name}:")
        if test_func():
            passed += 1
        else:
            print(f"âš ï¸  {test_name} fallÃ³")
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š RESULTADO: {passed}/{total} pruebas pasaron")
    
    if passed == total:
        print("ğŸ‰ Â¡Todas las pruebas pasaron! El sistema estÃ¡ listo para la evaluaciÃ³n.")
        print("\nğŸ’¡ Para ejecutar la evaluaciÃ³n completa:")
        print("   cd src/evaluation")
        print("   python evaluate_ragas.py")
    else:
        print("âŒ Algunas pruebas fallaron. Revisa los errores antes de continuar.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
